{"updatedAt": "2025-11-28T03:29:56.896Z", "createdAt": "2025-11-25T07:37:54.834Z", "id": "zvMZe5epwZfvuVI0", "name": "Multi-AI Research Pipeline v2 - Orchestrated", "description": null, "active": false, "isArchived": false, "nodes": [{"parameters": {"path": "ai-research-v2", "formTitle": "AI Research Assistant", "formDescription": "Ask a question to multiple AI models with intelligent orchestration", "formFields": {"values": [{"fieldLabel": "Research Question", "fieldType": "textarea", "placeholder": "Enter your research question here. Be specific for better results...", "requiredField": true}, {"fieldLabel": "Research Mode", "fieldType": "dropdown", "fieldOptions": {"values": [{"option": "Quick Thinking (Fast, ~2 min)"}, {"option": "Deep Research (Thorough, ~10 min)"}]}, "requiredField": true}, {"fieldLabel": "Session Name (Optional)", "placeholder": "Name this research session"}]}, "responseMode": "responseNode", "options": {}}, "id": "form-trigger", "name": "Research Form", "type": "n8n-nodes-base.formTrigger", "typeVersion": 2.1, "position": [0, 304], "webhookId": "ai-research-v2"}, {"parameters": {"jsCode": "// Initialize session\nconst formData = $input.first()?.json || {};\nconst modeString = formData['Research Mode'] || '';\nconst isDeepResearch = modeString.includes('Deep');\n\nconst sessionId = Date.now().toString(36) + Math.random().toString(36).substr(2);\nconst timestamp = new Date().toISOString();\n\n// Model configurations - EDIT IN THE PYTHON SCRIPT\nconst quickModels = [\n  {\n    \"id\": \"haiku\",\n    \"model\": \"anthropic/claude-haiku-4.5\",\n    \"name\": \"Claude Haiku 4.5\",\n    \"maxTokens\": 4000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true,\n      \"type\": \"extended\"\n    }\n  },\n  {\n    \"id\": \"gemini-flash\",\n    \"model\": \"google/gemini-2.5-flash-preview-09-2025\",\n    \"name\": \"Gemini 2.5 Flash\",\n    \"maxTokens\": 4000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true\n    }\n  },\n  {\n    \"id\": \"deepseek\",\n    \"model\": \"deepseek/deepseek-r1\",\n    \"name\": \"DeepSeek R1\",\n    \"maxTokens\": 4000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"builtin\": true\n    }\n  },\n  {\n    \"id\": \"grok\",\n    \"model\": \"x-ai/grok-4.1-fast:free\",\n    \"name\": \"Grok 4.1 Fast\",\n    \"maxTokens\": 4000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true\n    }\n  }\n];\n\nconst deepModels = [\n  {\n    \"id\": \"opus\",\n    \"model\": \"anthropic/claude-opus-4.5\",\n    \"name\": \"Claude Opus 4.5\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true,\n      \"type\": \"extended\"\n    }\n  },\n  {\n    \"id\": \"sonnet\",\n    \"model\": \"anthropic/claude-4-sonnet-20250522\",\n    \"name\": \"Claude Sonnet 4.5\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true,\n      \"type\": \"extended\"\n    }\n  },\n  {\n    \"id\": \"gpt51\",\n    \"model\": \"openai/gpt-5.1\",\n    \"name\": \"GPT-5.1\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true\n    }\n  },\n  {\n    \"id\": \"gemini3\",\n    \"model\": \"google/gemini-3-pro-preview\",\n    \"name\": \"Gemini 3 Pro\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"enabled\": true\n    }\n  },\n  {\n    \"id\": \"kimi\",\n    \"model\": \"moonshotai/kimi-k2-thinking\",\n    \"name\": \"Kimi K2 Thinking\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"builtin\": true\n    }\n  },\n  {\n    \"id\": \"perplexity\",\n    \"model\": \"perplexity/sonar-deep-research\",\n    \"name\": \"Perplexity Deep Research\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"builtin\": true\n    }\n  },\n  {\n    \"id\": \"deepseek-r1\",\n    \"model\": \"deepseek/deepseek-r1\",\n    \"name\": \"DeepSeek R1\",\n    \"maxTokens\": 8000,\n    \"temperature\": 0.7,\n    \"thinking\": {\n      \"builtin\": true\n    }\n  }\n];\n\nconst orchestrator = {\n  \"model\": \"anthropic/claude-4-sonnet-20250522\",\n  \"name\": \"Sonnet 4.5 Orchestrator\",\n  \"maxTokens\": 100000,\n  \"temperature\": 0.3,\n  \"thinking\": {\n    \"enabled\": true,\n    \"type\": \"extended\"\n  }\n};\n\nconst savePath = \"/processed\";\n\nreturn {\n  json: {\n    sessionId,\n    sessionName: formData['Session Name (Optional)'] || `Research-${sessionId}`,\n    question: formData['Research Question'] || '',\n    mode: isDeepResearch ? 'deep' : 'quick',\n    timestamp,\n    models: isDeepResearch ? deepModels : quickModels,\n    orchestrator,\n    savePath,\n    responses: [],\n    revisionCount: 0,\n    maxRevisions: 2\n  }\n};"}, "id": "init-session", "name": "Initialize Session", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [224, 304], "notes": "\u26a0\ufe0f TO CHANGE MODELS: Edit update-models.py in the researcher folder, then run: python3 update-models.py"}, {"parameters": {"jsCode": "// Prepare items for parallel model calls\nconst session = $input.first().json;\nconst items = [];\n\n// Note: session.models comes from Initialize Session\nfor (const config of session.models) {\n  // Build the OpenRouter request body\n  const requestBody = {\n    model: config.model,\n    messages: [\n      {\n        role: 'system',\n        content: config.systemPrompt || `You are an expert research assistant with deep knowledge across many domains. Your role is to provide thorough, well-reasoned answers.\n\nGUIDELINES:\n- Draw from your extensive knowledge base to provide substantive, helpful answers\n- Be direct and confident - share what you know without excessive hedging\n- Structure responses clearly with key points, examples, and reasoning\n- If something changes frequently (prices, APIs, versions), briefly note info may be dated\n- For factual claims, cite known sources where appropriate\n\nDO NOT:\n- Refuse to answer because you \"cannot browse the web in real-time\"\n- Add disclaimers like \"I cannot verify current availability\"  \n- Hedge every statement with limitations\n- Say \"I don't have access to\" when you can answer from knowledge\n\nRESPONSE FORMAT:\n- 400-600 words\n- Use markdown: ## headers, **bold** for key terms, bullet points\n- Lead with the most important information\n- End with practical takeaways`\n      },\n      {\n        role: 'user',\n        content: session.question\n      }\n    ],\n    max_tokens: config.maxTokens || 4000,\n    temperature: config.temperature || 0.7\n  };\n  \n  // Add thinking parameters based on model config\n  if (config.thinking?.enabled) {\n    if (config.thinking.type === 'extended') {\n      // Claude extended thinking format\n      requestBody.thinking = { type: 'enabled', budget_tokens: 10000 };\n    } else {\n      // Generic thinking mode\n      requestBody.thinking = true;\n    }\n  }\n  // Models with builtin thinking (DeepSeek R1, Kimi, Perplexity) don't need extra params\n  \n  items.push({\n    json: {\n      ...session,\n      currentModel: config,\n      requestBody: requestBody,\n      correctionInstructions: null\n    }\n  });\n}\n\nreturn items;"}, "id": "split-for-models", "name": "Split for Models", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [448, 304]}, {"parameters": {"method": "POST", "url": "https://openrouter.ai/api/v1/chat/completions", "authentication": "genericCredentialType", "genericAuthType": "httpHeaderAuth", "sendHeaders": true, "headerParameters": {"parameters": [{"name": "HTTP-Referer", "value": "http://localhost:5678"}, {"name": "X-Title", "value": "n8n Research Pipeline"}]}, "sendBody": true, "specifyBody": "json", "jsonBody": "={{ JSON.stringify($json.requestBody) }}", "options": {"response": {"response": {"fullResponse": true, "neverError": true}}, "timeout": "={{ $json.currentModel.timeout }}"}}, "id": "call-openrouter", "name": "Call OpenRouter", "type": "n8n-nodes-base.httpRequest", "typeVersion": 4.2, "position": [672, 304], "credentials": {"httpHeaderAuth": {"id": "HaoSKA3ZQDFm19Sk", "name": "OpenRouter API"}}}, {"parameters": {"jsCode": "// Parse response and track success/failure\nconst input = $input.first().json;\nconst httpResponse = input.body || input;\nconst session = $('Split for Models').first().json;\nconst currentModel = session.currentModel;\n\nlet response = {\n  modelId: currentModel.id,\n  modelName: currentModel.name,\n  model: currentModel.model,\n  success: false,\n  content: null,\n  error: null,\n  tokenUsage: null,\n  responseTime: null\n};\n\ntry {\n  if (httpResponse.error) {\n    response.error = httpResponse.error.message || 'API Error';\n    response.errorType = 'api_error';\n  } else if (httpResponse.choices && httpResponse.choices[0]) {\n    const content = httpResponse.choices[0].message?.content || '';\n    response.success = true;\n    response.content = content;\n    response.tokenUsage = httpResponse.usage;\n    \n    // Basic quality checks\n    if (content.length < 100) {\n      response.qualityFlag = 'too_short';\n    }\n  } else {\n    response.error = 'Invalid response structure';\n    response.errorType = 'parse_error';\n  }\n} catch (e) {\n  response.error = e.message;\n  response.errorType = 'exception';\n}\n\nreturn {\n  json: {\n    ...session,\n    response\n  }\n};"}, "id": "parse-response", "name": "Parse Response", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [880, 304]}, {"parameters": {"aggregate": "aggregateAllItemData", "destinationFieldName": "allResponses", "include": "allFieldsExcept", "fieldsToExclude": "modelConfigs", "options": {}}, "id": "aggregate-responses", "name": "Aggregate Responses", "type": "n8n-nodes-base.aggregate", "typeVersion": 1, "position": [1104, 304]}, {"parameters": {"jsCode": "// Prepare data for orchestrator evaluation\nconst aggregated = $input.first().json;\nconst allResponses = aggregated.allResponses || [];\n\nconst firstItem = allResponses[0] || {};\nconst sessionData = {\n  sessionId: firstItem.sessionId,\n  question: firstItem.question,\n  sessionName: firstItem.sessionName,\n  mode: firstItem.mode,\n  revisionCount: firstItem.revisionCount || 0,\n  maxRevisions: firstItem.maxRevisions || 2,\n  models: firstItem.models || [],\n  savePath: firstItem.savePath || \"/processed\"\n};\n\nconst responses = allResponses.map(item => item.response).filter(r => r);\nconst successfulResponses = responses.filter(r => r.success && !r.qualityFlag);\nconst failedResponses = responses.filter(r => !r.success);\nconst lowQualityResponses = responses.filter(r => r.success && r.qualityFlag);\n\n// Build response summaries safely\nconst responseSummaries = responses.map(r => {\n  const content = r.content ? r.content.substring(0, 1200).replace(/\"/g, \"'\") : 'NO CONTENT';\n  return '--- ' + r.modelName + ' (' + r.modelId + ') ---\\nSuccess: ' + r.success + '\\nError: ' + (r.error || 'none') + '\\nContent: ' + content;\n}).join('\\n\\n');\n\nconst userMsg = 'QUESTION: ' + sessionData.question + '\\n\\nRESPONSES:\\n' + responseSummaries + '\\n\\nRevision count: ' + sessionData.revisionCount + '/' + sessionData.maxRevisions;\n\nconst orchestratorRequestBody = {\n  model: 'anthropic/claude-4-sonnet-20250522',\n  messages: [\n    {\n      role: 'system',\n      content: 'You are a research quality orchestrator. Evaluate if responses answer the question. Return JSON: {\"evaluation\":{\"allAcceptable\":bool,\"summary\":\"text\",\"responseEvaluations\":[{\"modelId\":\"id\",\"modelName\":\"name\",\"acceptable\":bool,\"issues\":[],\"correctionInstructions\":\"text if needed\"}]},\"needsRevision\":bool,\"modelsToRevise\":[\"ids\"]}'\n    },\n    { role: 'user', content: userMsg }\n  ],\n  max_tokens: 2000,\n  temperature: 0.3,\n  thinking: { type: 'enabled', budget_tokens: 10000 }\n};\n\nreturn {\n  json: {\n    ...sessionData,\n    responses,\n    successfulResponses,\n    failedResponses,\n    lowQualityResponses,\n    totalModels: responses.length,\n    successCount: successfulResponses.length,\n    failureCount: failedResponses.length,\n    lowQualityCount: lowQualityResponses.length,\n    orchestratorRequestBody\n  }\n};"}, "id": "prepare-for-orchestrator", "name": "Prepare for Orchestrator", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [1328, 304]}, {"parameters": {"method": "POST", "url": "https://openrouter.ai/api/v1/chat/completions", "authentication": "genericCredentialType", "genericAuthType": "httpHeaderAuth", "sendHeaders": true, "headerParameters": {"parameters": [{"name": "HTTP-Referer", "value": "http://localhost:5678"}, {"name": "X-Title", "value": "n8n Research Orchestrator"}]}, "sendBody": true, "specifyBody": "json", "jsonBody": "={{ JSON.stringify($json.orchestratorRequestBody) }}", "options": {"response": {"response": {"fullResponse": true}}, "timeout": 120000}}, "id": "orchestrator-evaluate", "name": "Orchestrator Evaluate", "type": "n8n-nodes-base.httpRequest", "typeVersion": 4.2, "position": [1552, 304], "credentials": {"httpHeaderAuth": {"id": "HaoSKA3ZQDFm19Sk", "name": "OpenRouter API"}}}, {"parameters": {"jsCode": "// Parse orchestrator evaluation and decide next action\nconst session = $('Prepare for Orchestrator').first().json;\nconst httpResponse = $input.first().json;\n\nlet evaluation = null;\nlet decision = 'proceed_to_summary'; // default\n\ntry {\n  const content = httpResponse.body?.choices?.[0]?.message?.content || httpResponse.choices?.[0]?.message?.content || '';\n  \n  // Try to parse JSON from response\n  const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n  if (jsonMatch) {\n    evaluation = JSON.parse(jsonMatch[0]);\n  }\n} catch (e) {\n  console.log('Failed to parse orchestrator response:', e.message);\n}\n\n// Determine next action\nlet modelsToRevise = [];\nlet correctionInstructions = {};\n\nif (evaluation && evaluation.needsRevision) {\n  // Check if we've hit revision cap\n  if (session.revisionCount >= session.maxRevisions) {\n    decision = 'human_review_required';\n  } else {\n    decision = 'revision_needed';\n    modelsToRevise = evaluation.modelsToRevise || [];\n    \n    // Extract correction instructions for each model\n    if (evaluation.evaluation?.responseEvaluations) {\n      for (const evalItem of evaluation.evaluation.responseEvaluations) {\n        if (!evalItem.acceptable && evalItem.correctionInstructions) {\n          correctionInstructions[evalItem.modelId] = evalItem.correctionInstructions;\n        }\n      }\n    }\n  }\n}\n\n// Check for hard failures (API errors) - don't retry these\nconst hardFailures = session.failedResponses.filter(r => r.errorType === 'api_error');\nif (hardFailures.length > 0 && modelsToRevise.length === 0) {\n  // Only hard failures, no quality issues - proceed but flag\n  decision = session.successCount > 0 ? 'proceed_to_summary' : 'human_review_required';\n}\n\n// Build summary request body for later use\nconst successResponses = (session.responses || []).filter(r => r.success);\nconst responseText = successResponses.map(r => \n  '## ' + (r.modelName || 'Unknown') + '\\n' + (r.content || 'No content')\n).join('\\n\\n---\\n\\n');\n\nconst summaryRequestBody = {\n  model: 'anthropic/claude-4-sonnet-20250522',\n  messages: [\n    {\n      role: 'system',\n      content: 'You are an expert research synthesizer. Create a comprehensive summary with: 1) Key themes 2) Areas of consensus 3) Notable disagreements 4) Actionable insights. Use markdown formatting.'\n    },\n    {\n      role: 'user',\n      content: 'RESEARCH QUESTION: ' + session.question + '\\n\\nMODEL RESPONSES:\\n' + responseText + '\\n\\nPlease synthesize these responses into a comprehensive summary.'\n    }\n  ],\n  max_tokens: 4000,\n  temperature: 0.5,\n  thinking: { type: 'enabled', budget_tokens: 10000 }\n};\n\nreturn {\n  json: {\n    ...session,\n    evaluation,\n    decision,\n    modelsToRevise,\n    correctionInstructions,\n    summaryRequestBody,\n    revisionCount: session.revisionCount + (decision === 'revision_needed' ? 1 : 0)\n  }\n};"}, "id": "parse-orchestrator", "name": "Parse Orchestrator Decision", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [1760, 304]}, {"parameters": {"rules": {"values": [{"conditions": {"options": {"caseSensitive": true, "leftValue": "", "typeValidation": "strict"}, "conditions": [{"leftValue": "", "rightValue": "", "operator": {"type": "string", "operation": "equals"}}], "combinator": "and"}}]}, "options": {}}, "id": "decision-switch", "name": "Decision Router", "type": "n8n-nodes-base.switch", "typeVersion": 3, "position": [1984, 304]}, {"parameters": {"jsCode": "// Prepare re-query for models that need revision\nconst session = $input.first().json;\nconst modelsToRevise = session.modelsToRevise || [];\nconst corrections = session.correctionInstructions || {};\n\n// Get the model configs for models that need revision\nconst items = [];\nfor (const modelId of modelsToRevise) {\n  const modelConfig = (session.models || []).find(m => m.id === modelId);\n  if (modelConfig) {\n    // Build the revision request body\n    const requestBody = {\n      model: modelConfig.model,\n      messages: [\n        {\n          role: 'system',\n          content: (modelConfig.systemPrompt || 'You are a helpful research assistant.') + \n            '\\n\\nIMPORTANT - REVISION REQUEST: Your previous response had issues. ' + \n            (corrections[modelId] || 'Please provide a more thorough, on-topic response.')\n        },\n        {\n          role: 'user',\n          content: session.question\n        }\n      ],\n      max_tokens: modelConfig.maxTokens || 4000,\n      temperature: modelConfig.temperature || 0.7\n    };\n    \n    // Add thinking parameters\n    if (modelConfig.thinking?.enabled) {\n      if (modelConfig.thinking.type === 'extended') {\n        requestBody.thinking = { type: 'enabled', budget_tokens: 10000 };\n      } else {\n        requestBody.thinking = true;\n      }\n    }\n    \n    items.push({\n      json: {\n        ...session,\n        currentModel: modelConfig,\n        requestBody: requestBody,\n        correctionInstructions: corrections[modelId] || 'Please provide a more thorough, on-topic response.',\n        isRevision: true\n      }\n    });\n  }\n}\n\nif (items.length === 0) {\n  // No models to revise, shouldn't happen but handle gracefully\n  return [{ json: { ...session, skipRevision: true } }];\n}\n\nreturn items;"}, "id": "prepare-revision", "name": "Prepare Revision", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [2208, 400]}, {"parameters": {"method": "POST", "url": "https://openrouter.ai/api/v1/chat/completions", "authentication": "genericCredentialType", "genericAuthType": "httpHeaderAuth", "sendHeaders": true, "headerParameters": {"parameters": [{"name": "HTTP-Referer", "value": "http://localhost:5678"}, {"name": "X-Title", "value": "n8n Research Revision"}]}, "sendBody": true, "specifyBody": "json", "jsonBody": "={{ JSON.stringify($json.requestBody) }}", "options": {"response": {"response": {"fullResponse": true, "neverError": true}}, "timeout": "={{ $json.currentModel.timeout }}"}}, "id": "revision-call", "name": "Revision Call", "type": "n8n-nodes-base.httpRequest", "typeVersion": 4.2, "position": [2432, 400], "credentials": {"httpHeaderAuth": {"id": "HaoSKA3ZQDFm19Sk", "name": "OpenRouter API"}}}, {"parameters": {"jsCode": "// Parse revision response and merge back\nconst input = $input.first().json;\nconst httpResponse = input.body || input;\nconst session = $('Prepare Revision').first().json;\nconst currentModel = session.currentModel;\n\nlet response = {\n  modelId: currentModel.id,\n  modelName: currentModel.name,\n  model: currentModel.model,\n  success: false,\n  content: null,\n  error: null,\n  isRevision: true,\n  revisionNumber: session.revisionCount\n};\n\ntry {\n  if (httpResponse.choices && httpResponse.choices[0]) {\n    response.success = true;\n    response.content = httpResponse.choices[0].message?.content || '';\n    response.tokenUsage = httpResponse.usage;\n  } else if (httpResponse.error) {\n    response.error = httpResponse.error.message || 'Revision API Error';\n  }\n} catch (e) {\n  response.error = e.message;\n}\n\n// Update the responses array - replace the old response for this model\nconst updatedResponses = session.responses.map(r => \n  r.modelId === currentModel.id ? response : r\n);\n\nreturn {\n  json: {\n    ...session,\n    responses: updatedResponses,\n    lastRevision: response\n  }\n};"}, "id": "parse-revision", "name": "Parse Revision", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [2640, 400]}, {"parameters": {"aggregate": "aggregateAllItemData", "destinationFieldName": "revisedData", "include": "allFieldsExcept", "fieldsToExclude": "currentModel,correctionInstructions,isRevision", "options": {}}, "id": "aggregate-revisions", "name": "Aggregate Revisions", "type": "n8n-nodes-base.aggregate", "typeVersion": 1, "position": [2864, 400]}, {"parameters": {"jsCode": "// Merge revised responses back into session and loop back to orchestrator\nconst aggregated = $input.first().json;\nconst revisedData = aggregated.revisedData || [];\n\n// Take the latest session state with updated responses\nconst latestSession = revisedData[revisedData.length - 1] || revisedData[0];\n\n// Recalculate success/failure counts\nconst responses = latestSession.responses || [];\nconst successfulResponses = responses.filter(r => r.success && !r.qualityFlag);\nconst failedResponses = responses.filter(r => !r.success);\nconst lowQualityResponses = responses.filter(r => r.success && r.qualityFlag);\n\nreturn {\n  json: {\n    ...latestSession,\n    successfulResponses,\n    failedResponses,\n    lowQualityResponses,\n    successCount: successfulResponses.length,\n    failureCount: failedResponses.length,\n    lowQualityCount: lowQualityResponses.length\n  }\n};"}, "id": "merge-revisions", "name": "Merge Revisions", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [3088, 400]}, {"parameters": {"method": "POST", "url": "https://openrouter.ai/api/v1/chat/completions", "authentication": "genericCredentialType", "genericAuthType": "httpHeaderAuth", "sendHeaders": true, "headerParameters": {"parameters": [{"name": "HTTP-Referer", "value": "http://localhost:5678"}, {"name": "X-Title", "value": "n8n Research Summary"}]}, "sendBody": true, "specifyBody": "json", "jsonBody": "={{ JSON.stringify($json.summaryRequestBody) }}", "options": {"response": {"response": {"fullResponse": true}}, "timeout": 180000}}, "id": "generate-summary", "name": "Generate Summary", "type": "n8n-nodes-base.httpRequest", "typeVersion": 4.2, "position": [2208, 208], "credentials": {"httpHeaderAuth": {"id": "HaoSKA3ZQDFm19Sk", "name": "OpenRouter API"}}}, {"parameters": {"jsCode": "// Format final output for Obsidian - with nested folder structure\nconst session = $(\"Parse Orchestrator Decision\").first().json;\nconst summaryResponse = $input.first().json;\n\nconst summary = summaryResponse.body?.choices?.[0]?.message?.content || \n                summaryResponse.choices?.[0]?.message?.content || \n                \"Summary generation failed\";\n\nconst successfulResponses = session.responses.filter(r => r.success);\nconst now = new Date();\n\n// Build folder path: YYYY/MM MMM/YYYY-MM-DD ddd [research name]\nconst year = now.getFullYear().toString();\nconst monthNum = String(now.getMonth() + 1).padStart(2, \"0\");\nconst monthNames = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"];\nconst monthName = monthNames[now.getMonth()];\nconst dayNum = String(now.getDate()).padStart(2, \"0\");\nconst dayNames = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"];\nconst dayName = dayNames[now.getDay()];\n\n// Clean research name for folder (keep spaces, remove special chars)\nconst researchName = session.question\n  .substring(0, 50)\n  .replace(/[^a-zA-Z0-9\\s]/g, \"\")\n  .trim();\n\n// Build paths\nconst folderPath = `${year}/${monthNum} ${monthName}/${year}-${monthNum}-${dayNum} ${dayName} ${researchName}`;\nconst fullFolderPath = `/processed/${folderPath}`;\n\n// Build summary markdown\nconst summaryMd = `---\ntags:\n  - ai-research\n  - ${session.mode === \"deep\" ? \"deep-research\" : \"quick-thinking\"}\ndate: ${year}-${monthNum}-${dayNum}\nquestion: \"${session.question.replace(/\"/g, '\\\\\"').substring(0, 100)}\"\nmodels: [${successfulResponses.map(r => '\"' + (r.modelName.split(\"/\")[1] || r.modelName) + '\"').join(\", \")}]\nstatus: completed\n---\n\n# Research: ${session.question.substring(0, 80)}${session.question.length > 80 ? \"...\" : \"\"}\n\n> [!question] Research Question\n> ${session.question}\n\n## AI Synthesis\n\n${summary}\n\n---\n\n## Individual AI Responses\n\n${successfulResponses.map((r, i) => {\n  const modelShort = (r.modelName.split(\"/\")[1] || r.modelName).replace(/[^a-zA-Z0-9-]/g, \"-\");\n  const fileName = String(i + 1).padStart(2, \"0\") + \"-\" + modelShort;\n  return \"- [[\" + fileName + \"|\" + (r.modelName.split(\"/\")[1] || r.modelName) + \"]]\";\n}).join(\"\\n\")}\n\n---\n\n## Session Info\n\n| Field | Value |\n|-------|-------|\n| Session ID | \\`${session.sessionId}\\` |\n| Mode | ${session.mode} |\n| Models | ${successfulResponses.length} |\n| Timestamp | ${now.toISOString()} |\n`;\n\n// Build array of files\nconst files = [\n  {\n    filename: \"00-summary.md\",\n    content: summaryMd,\n    type: \"summary\"\n  }\n];\n\n// Add individual model response files\nsuccessfulResponses.forEach((response, index) => {\n  const modelShort = (response.modelName.split(\"/\")[1] || response.modelName).replace(/[^a-zA-Z0-9-]/g, \"-\");\n  const fileName = String(index + 1).padStart(2, \"0\") + \"-\" + modelShort + \".md\";\n  \n  const responseMd = `---\ntags:\n  - ai-response\n  - ${modelShort}\ndate: ${year}-${monthNum}-${dayNum}\nmodel: ${response.modelName}\nparent: \"[[00-summary]]\"\n---\n\n# ${response.modelName.split(\"/\")[1] || response.modelName}\n\n> [!info] Model Info\n> **Model:** ${response.modelName}\n> **Mode:** ${session.mode}${response.isRevision ? \"\\n> **Revised:** Yes\" : \"\"}\n\n## Response\n\n${response.content}\n\n---\n\n*Part of: [[00-summary|${session.question.substring(0, 40)}...]]*\n`;\n  \n  files.push({\n    filename: fileName,\n    content: responseMd,\n    type: \"response\",\n    model: modelShort\n  });\n});\n\nreturn {\n  json: {\n    folderPath: fullFolderPath,\n    files,\n    fileCount: files.length,\n    question: session.question\n  }\n};\n"}, "id": "format-output", "name": "Format Output", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [2432, 208]}, {"parameters": {"jsCode": "// Human review required - format for Slack/manual review\nconst session = $input.first().json;\n\nconst output = {\n  sessionId: session.sessionId,\n  sessionName: session.sessionName,\n  question: session.question,\n  mode: session.mode,\n  timestamp: session.timestamp,\n  \n  // Flag for human review\n  humanReviewRequired: true,\n  reviewReason: `Revision cap reached (${session.revisionCount}/${session.maxRevisions}). Some responses still have quality issues.`,\n  \n  // Orchestrator's assessment\n  orchestratorEvaluation: session.evaluation,\n  \n  // Current state of responses\n  responses: session.responses,\n  \n  // What needs attention\n  problemModels: session.modelsToRevise || [],\n  \n  // Stats\n  stats: {\n    totalModels: session.responses.length,\n    successfulResponses: session.successCount,\n    failedResponses: session.failureCount,\n    revisionsAttempted: session.revisionCount\n  }\n};\n\nreturn { json: output };"}, "id": "human-review-format", "name": "Format for Human Review", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [2208, 640]}, {"parameters": {"text": "=:warning: *Human Review Required*\\n\\n*Session:* {{ $json.sessionName }}\\n*Question:* {{ $json.question }}\\n\\n*Reason:* {{ $json.reviewReason }}\\n\\n*Problem Models:* {{ $json.problemModels.join(', ') }}\\n\\n*Stats:*\\n- Successful: {{ $json.stats.successfulResponses }}/{{ $json.stats.totalModels }}\\n- Revisions Attempted: {{ $json.stats.revisionsAttempted }}\\n\\nPlease review in n8n and decide how to proceed.", "otherOptions": {}}, "id": "slack-notify", "name": "Slack Notification", "type": "n8n-nodes-base.slack", "typeVersion": 2.1, "position": [2432, 640], "webhookId": "36d6ae23-3a49-4f96-9ad4-04a71190dddd", "credentials": {"slackApi": {"id": "SLACK_CREDENTIAL_ID", "name": "Slack API"}}, "disabled": true, "continueOnFail": true}, {"parameters": {"respondWith": "text", "responseBody": "={{ \"<!DOCTYPE html><html><head><title>Research Complete</title><style>body{font-family:system-ui,-apple-system,sans-serif;max-width:800px;margin:40px auto;padding:20px;line-height:1.6}h1{color:#2563eb}.success{background:#dcfce7;border:1px solid #16a34a;padding:20px;border-radius:8px;margin:20px 0}.info{background:#f0f9ff;border:1px solid #0284c7;padding:15px;border-radius:8px;margin:10px 0}code{background:#e5e7eb;padding:2px 6px;border-radius:4px;font-size:0.9em}pre{background:#1e293b;color:#e2e8f0;padding:15px;border-radius:8px;overflow-x:auto}.summary{background:#fefce8;border:1px solid #ca8a04;padding:15px;border-radius:8px;margin:20px 0}</style></head><body><h1>\u2705 Research Complete!</h1><div class=success><strong>Your research has been saved!</strong></div><div class=info><strong>\ud83d\udcc1 File saved:</strong><br><code>/processed/\" + $json.filename + \"</code></div><div class=summary><strong>\ud83d\udcdd Summary Preview:</strong><p>\" + ($json.summary || \"\").substring(0, 300).replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\") + \"...</p></div><p><strong>Next steps:</strong></p><ul><li>Find your file in the n8n processed folder</li><li>Copy to your Obsidian vault</li><li>Or set up auto-sync to your vault</li></ul><p style=color:#6b7280;font-size:0.9em>Session ID: \" + $json.sessionId + \"</p></body></html>\" }}", "options": {"responseHeaders": {"entries": [{"name": "Content-Type", "value": "text/html"}]}}}, "id": "respond-success", "name": "Respond Success", "type": "n8n-nodes-base.respondToWebhook", "typeVersion": 1, "position": [3184, 208]}, {"parameters": {"respondWith": "json", "responseBody": "={{ JSON.stringify($json) }}", "options": {}}, "id": "respond-review", "name": "Respond Human Review", "type": "n8n-nodes-base.respondToWebhook", "typeVersion": 1, "position": [2640, 640]}, {"parameters": {"jsCode": "// Prepare files with folder path for mkdir + save\nconst data = $input.first().json;\nconst folderPath = data.folderPath;\n\n// Return one item per file, include folder path for mkdir\nreturn data.files.map(file => ({\n  json: {\n    folderPath: folderPath,\n    filePath: folderPath + \"/\" + file.filename,\n    filename: file.filename,\n    type: file.type\n  },\n  binary: {\n    data: {\n      data: Buffer.from(file.content, \"utf8\").toString(\"base64\"),\n      mimeType: \"text/markdown\",\n      fileName: file.filename\n    }\n  }\n}));\n"}, "id": "convert-to-binary", "name": "Prepare Files", "type": "n8n-nodes-base.code", "typeVersion": 2, "position": [2640, 208]}, {"parameters": {"operation": "write", "fileName": "={{ $json.filePath }}", "options": {}}, "id": "write-file-node", "name": "Save to Obsidian", "type": "n8n-nodes-base.readWriteFile", "typeVersion": 1, "position": [2960, 208]}, {"parameters": {"command": "=mkdir -p \"{{ $json.folderPath }}\""}, "id": "create-folder-node", "name": "Create Folder", "type": "n8n-nodes-base.executeCommand", "typeVersion": 1, "position": [2752, 208]}], "connections": {"Research Form": {"main": [[{"node": "Initialize Session", "type": "main", "index": 0}]]}, "Initialize Session": {"main": [[{"node": "Split for Models", "type": "main", "index": 0}]]}, "Split for Models": {"main": [[{"node": "Call OpenRouter", "type": "main", "index": 0}]]}, "Call OpenRouter": {"main": [[{"node": "Parse Response", "type": "main", "index": 0}]]}, "Parse Response": {"main": [[{"node": "Aggregate Responses", "type": "main", "index": 0}]]}, "Aggregate Responses": {"main": [[{"node": "Prepare for Orchestrator", "type": "main", "index": 0}]]}, "Prepare for Orchestrator": {"main": [[{"node": "Orchestrator Evaluate", "type": "main", "index": 0}]]}, "Orchestrator Evaluate": {"main": [[{"node": "Parse Orchestrator Decision", "type": "main", "index": 0}]]}, "Parse Orchestrator Decision": {"main": [[{"node": "Decision Router", "type": "main", "index": 0}]]}, "Decision Router": {"main": [[{"node": "Generate Summary", "type": "main", "index": 0}], [{"node": "Prepare Revision", "type": "main", "index": 0}], [{"node": "Format for Human Review", "type": "main", "index": 0}]]}, "Prepare Revision": {"main": [[{"node": "Revision Call", "type": "main", "index": 0}]]}, "Revision Call": {"main": [[{"node": "Parse Revision", "type": "main", "index": 0}]]}, "Parse Revision": {"main": [[{"node": "Aggregate Revisions", "type": "main", "index": 0}]]}, "Aggregate Revisions": {"main": [[{"node": "Merge Revisions", "type": "main", "index": 0}]]}, "Merge Revisions": {"main": [[{"node": "Orchestrator Evaluate", "type": "main", "index": 0}]]}, "Generate Summary": {"main": [[{"node": "Format Output", "type": "main", "index": 0}]]}, "Format Output": {"main": [[{"node": "Prepare Files", "type": "main", "index": 0}]]}, "Format for Human Review": {"main": [[{"node": "Slack Notification", "type": "main", "index": 0}]]}, "Slack Notification": {"main": [[{"node": "Respond Human Review", "type": "main", "index": 0}]]}, "Prepare Files": {"main": [[{"node": "Create Folder", "type": "main", "index": 0}]]}, "Save to Obsidian": {"main": [[{"node": "Respond Success", "type": "main", "index": 0}]]}, "Create Folder": {"main": [[{"node": "Save to Obsidian", "type": "main", "index": 0}]]}}, "settings": {"executionOrder": "v1", "callerPolicy": "workflowsFromSameOwner", "availableInMCP": false}, "staticData": null, "meta": null, "pinData": {}, "versionId": "e5ce1248-b72e-47dd-a324-aac915360a81", "versionCounter": 22, "triggerCount": 0, "shared": [{"updatedAt": "2025-11-25T07:37:54.858Z", "createdAt": "2025-11-25T07:37:54.858Z", "role": "workflow:owner", "workflowId": "zvMZe5epwZfvuVI0", "projectId": "YsF35y2Ejzp27klu", "project": {"updatedAt": "2025-11-25T07:22:50.672Z", "createdAt": "2025-11-25T07:21:04.628Z", "id": "YsF35y2Ejzp27klu", "name": "Kevin HG <kevn.hg@gmail.com>", "type": "personal", "icon": null, "description": null, "projectRelations": [{"updatedAt": "2025-11-25T07:21:04.629Z", "createdAt": "2025-11-25T07:21:04.629Z", "userId": "3347384b-043e-4907-9c54-128980f0c44b", "projectId": "YsF35y2Ejzp27klu", "user": {"updatedAt": "2025-11-27T23:59:27.000Z", "createdAt": "2025-11-25T07:21:03.191Z", "id": "3347384b-043e-4907-9c54-128980f0c44b", "email": "kevn.hg@gmail.com", "firstName": "Kevin", "lastName": "HG", "personalizationAnswers": null, "settings": {"userActivated": false}, "disabled": false, "mfaEnabled": false, "lastActiveAt": "2025-11-27", "isPending": false}}]}}], "tags": []}